{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e812ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "#Visualization libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c0aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset\n",
    "df1=pd.read_csv(\"D:\\Techmiya\\PRoject\\Datasets\\hatespeech\\labeled_data.csv\")\n",
    "df2=pd.read_csv(\"HOT_preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7144e4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c4edc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>neither</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "      <td>neither</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "      <td>neither</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text            category  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...             neither   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  offensive_language   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  offensive_language   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  offensive_language   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  offensive_language   \n",
       "...                                                  ...                 ...   \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  offensive_language   \n",
       "24779  you've gone and broke the wrong heart baby, an...             neither   \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  offensive_language   \n",
       "24781              youu got wild bitches tellin you lies  offensive_language   \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...             neither   \n",
       "\n",
       "       label  \n",
       "0          2  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "24778      1  \n",
       "24779      2  \n",
       "24780      1  \n",
       "24781      1  \n",
       "24782      2  \n",
       "\n",
       "[24783 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Doing some adjustments\n",
    "\n",
    "c=df1['class']\n",
    "df1.rename(columns={'tweet' : 'text',\n",
    "                   'class' : 'category'}, \n",
    "                    inplace=True)\n",
    "a=df1['text']\n",
    "b=df1['category'].map({0: 'hate_speech', 1: 'offensive_language',2: 'neither'})\n",
    "\n",
    "df= pd.concat([a,b,c], axis=1)\n",
    "df.rename(columns={'class' : 'label'}, \n",
    "                    inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ccd71fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19190</td>\n",
       "      <td>19190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4163</td>\n",
       "      <td>4163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text  category\n",
       "label                 \n",
       "0       1430      1430\n",
       "1      19190     19190\n",
       "2       4163      4163"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping data by label\n",
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df125afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_text</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haa</td>\n",
       "      <td>0</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banti empowered woman feminism gyan pelti din ...</td>\n",
       "      <td>2</td>\n",
       "      <td>banti empowered adult female feminism gyan pel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usko chhod mjse bat baap gya ldki beech madarchod</td>\n",
       "      <td>2</td>\n",
       "      <td>usko chhod mjse words father gya ldki midway m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>punjab madarchodon khila nokrian day imran</td>\n",
       "      <td>2</td>\n",
       "      <td>punjab mother fucker khila nokrian day imran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chill maar madarchod gand maar lene</td>\n",
       "      <td>2</td>\n",
       "      <td>chill kill motherfucker ass kill lene</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            old_text  score  \\\n",
       "0                                                haa      0   \n",
       "1  banti empowered woman feminism gyan pelti din ...      2   \n",
       "2  usko chhod mjse bat baap gya ldki beech madarchod      2   \n",
       "3         punjab madarchodon khila nokrian day imran      2   \n",
       "4                chill maar madarchod gand maar lene      2   \n",
       "\n",
       "                                                text  \n",
       "0                                                 ha  \n",
       "1  banti empowered adult female feminism gyan pel...  \n",
       "2  usko chhod mjse words father gya ldki midway m...  \n",
       "3       punjab mother fucker khila nokrian day imran  \n",
       "4              chill kill motherfucker ass kill lene  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4cdfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the values to ease understanding. (Assigning 1 to Positive sentiment 4)\n",
    "df2['score'] = df2['score'].replace([0,1,2],[2,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bede99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c494f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_text</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haa</td>\n",
       "      <td>2</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banti empowered woman feminism gyan pelti din ...</td>\n",
       "      <td>1</td>\n",
       "      <td>banti empowered adult female feminism gyan pel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usko chhod mjse bat baap gya ldki beech madarchod</td>\n",
       "      <td>1</td>\n",
       "      <td>usko chhod mjse words father gya ldki midway m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>punjab madarchodon khila nokrian day imran</td>\n",
       "      <td>1</td>\n",
       "      <td>punjab mother fucker khila nokrian day imran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chill maar madarchod gand maar lene</td>\n",
       "      <td>1</td>\n",
       "      <td>chill kill motherfucker ass kill lene</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            old_text  score  \\\n",
       "0                                                haa      2   \n",
       "1  banti empowered woman feminism gyan pelti din ...      1   \n",
       "2  usko chhod mjse bat baap gya ldki beech madarchod      1   \n",
       "3         punjab madarchodon khila nokrian day imran      1   \n",
       "4                chill maar madarchod gand maar lene      1   \n",
       "\n",
       "                                                text  \n",
       "0                                                 ha  \n",
       "1  banti empowered adult female feminism gyan pel...  \n",
       "2  usko chhod mjse words father gya ldki midway m...  \n",
       "3       punjab mother fucker khila nokrian day imran  \n",
       "4              chill kill motherfucker ass kill lene  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0976cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['category'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf26607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.drop(['old_text'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0d3a068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>banti empowered adult female feminism gyan pel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>usko chhod mjse words father gya ldki midway m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>punjab mother fucker khila nokrian day imran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>chill kill motherfucker ass kill lene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>islamic kashmiri muslim terrorist pig jisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>love muslim terrorist killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0</td>\n",
       "      <td>mother fucker whore aullad islamic muslim ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>0</td>\n",
       "      <td>muslim terrorist dog double end aane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>0</td>\n",
       "      <td>madam hindu muslim terrorist dawood united india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                               text\n",
       "0         2                                                 ha\n",
       "1         1  banti empowered adult female feminism gyan pel...\n",
       "2         1  usko chhod mjse words father gya ldki midway m...\n",
       "3         1       punjab mother fucker khila nokrian day imran\n",
       "4         1              chill kill motherfucker ass kill lene\n",
       "...     ...                                                ...\n",
       "2998      0         islamic kashmiri muslim terrorist pig jisk\n",
       "2999      0                       love muslim terrorist killed\n",
       "3000      0   mother fucker whore aullad islamic muslim ter...\n",
       "3001      0               muslim terrorist dog double end aane\n",
       "3002      0   madam hindu muslim terrorist dawood united india\n",
       "\n",
       "[3003 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6edc40bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns = {'score':'label'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc90de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>banti empowered adult female feminism gyan pel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>usko chhod mjse words father gya ldki midway m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>punjab mother fucker khila nokrian day imran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>chill kill motherfucker ass kill lene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>islamic kashmiri muslim terrorist pig jisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>love muslim terrorist killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0</td>\n",
       "      <td>mother fucker whore aullad islamic muslim ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>0</td>\n",
       "      <td>muslim terrorist dog double end aane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>0</td>\n",
       "      <td>madam hindu muslim terrorist dawood united india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         2                                                 ha\n",
       "1         1  banti empowered adult female feminism gyan pel...\n",
       "2         1  usko chhod mjse words father gya ldki midway m...\n",
       "3         1       punjab mother fucker khila nokrian day imran\n",
       "4         1              chill kill motherfucker ass kill lene\n",
       "...     ...                                                ...\n",
       "2998      0         islamic kashmiri muslim terrorist pig jisk\n",
       "2999      0                       love muslim terrorist killed\n",
       "3000      0   mother fucker whore aullad islamic muslim ter...\n",
       "3001      0               muslim terrorist dog double end aane\n",
       "3002      0   madam hindu muslim terrorist dawood united india\n",
       "\n",
       "[3003 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc27097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df,df2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "048698a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>islamic kashmiri muslim terrorist pig jisk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>love muslim terrorist killed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>mother fucker whore aullad islamic muslim ter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>muslim terrorist dog double end aane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>madam hindu muslim terrorist dawood united india</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27786 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
       "1     !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
       "2     !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
       "3     !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1\n",
       "...                                                 ...    ...\n",
       "2998         islamic kashmiri muslim terrorist pig jisk      0\n",
       "2999                       love muslim terrorist killed      0\n",
       "3000   mother fucker whore aullad islamic muslim ter...      0\n",
       "3001               muslim terrorist dog double end aane      0\n",
       "3002   madam hindu muslim terrorist dawood united india      0\n",
       "\n",
       "[27786 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b6612dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "label       \n",
       "0       1732\n",
       "1      20951\n",
       "2       5103"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping data by label\n",
    "data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47d918a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88ebecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot('label',data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d488fc1d",
   "metadata": {},
   "source": [
    "# Cleaning the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a168cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a copy \n",
    "clean_reviews=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "001cec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_cleaning(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "281b8531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt mayasolovely as a woman you shouldnt compl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt  boy dats coldtyga dwn bad for cuffin dat ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt urkindofbrand dawg rt  you ever fuck a bit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt cganderson vivabased she look like a tranny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt shenikaroberts the shit you hear about me ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   rt mayasolovely as a woman you shouldnt compl...      2\n",
       "1   rt  boy dats coldtyga dwn bad for cuffin dat ...      1\n",
       "2   rt urkindofbrand dawg rt  you ever fuck a bit...      1\n",
       "3     rt cganderson vivabased she look like a tranny      1\n",
       "4   rt shenikaroberts the shit you hear about me ...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']=data['text'].apply(lambda x:review_cleaning(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e1d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dd9b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= ['yourselves', 'between', 'whom', 'itself', 'is', \"she's\", 'up', 'herself', 'here', 'your', 'each', \n",
    "             'we', 'he', 'my', \"you've\", 'having', 'in', 'both', 'for', 'themselves', 'are', 'them', 'other',\n",
    "             'and', 'an', 'during', 'their', 'can', 'yourself', 'she', 'until', 'so', 'these', 'ours', 'above', \n",
    "             'what', 'while', 'have', 're', 'more', 'only', \"needn't\", 'when', 'just', 'that', 'were', \"don't\", \n",
    "             'very', 'should', 'any', 'y', 'isn', 'who',  'a', 'they', 'to', 'too', \"should've\", 'has', 'before',\n",
    "             'into', 'yours', \"it's\", 'do', 'against', 'on',  'now', 'her', 've', 'd', 'by', 'am', 'from', \n",
    "             'about', 'further', \"that'll\", \"you'd\", 'you', 'as', 'how', 'been', 'the', 'or', 'doing', 'such',\n",
    "             'his', 'himself', 'ourselves',  'was', 'through', 'out', 'below', 'own', 'myself', 'theirs', \n",
    "             'me', 'why', 'once',  'him', 'than', 'be', 'most', \"you'll\", 'same', 'some', 'with', 'few', 'it',\n",
    "             'at', 'after', 'its', 'which', 'there','our', 'this', 'hers', 'being', 'did', 'of', 'had', 'under',\n",
    "             'over','again', 'where', 'those', 'then', \"you're\", 'i', 'because', 'does', 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec527bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3941481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating input feature and label\n",
    "X=data.text\n",
    "y=data.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06ad26",
   "metadata": {},
   "source": [
    "# spliting the dataset for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2f7e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47498a",
   "metadata": {},
   "source": [
    "# Transforming Dataset using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a95886d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of feature_words:  25000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Fit the TF-IDF Vectorizer\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=25000)\n",
    "vectoriser.fit(X_train)\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59bc61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the data using TF-IDF Vectorizer\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e463743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "classifier_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb95706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  81  202   45]\n",
      " [  44 4046  121]\n",
      " [  13  197  809]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.25      0.35       328\n",
      "           1       0.91      0.96      0.93      4211\n",
      "           2       0.83      0.79      0.81      1019\n",
      "\n",
      "    accuracy                           0.89      5558\n",
      "   macro avg       0.78      0.67      0.70      5558\n",
      "weighted avg       0.88      0.89      0.88      5558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "y_pred_rf = classifier_rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a57aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "#apply knn algorithm\n",
    "classifier= KNeighborsClassifier(n_neighbors=7)  \n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred= classifier.predict(X_test) \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "cm= confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af3209f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  31   35  262]\n",
      " [  25  890 3296]\n",
      " [   2   71  946]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "126955a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.09      0.16       328\n",
      "           1       0.89      0.21      0.34      4211\n",
      "           2       0.21      0.93      0.34      1019\n",
      "\n",
      "    accuracy                           0.34      5558\n",
      "   macro avg       0.55      0.41      0.28      5558\n",
      "weighted avg       0.75      0.34      0.33      5558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bceac559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91ae1d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 115  177   36]\n",
      " [ 131 3926  154]\n",
      " [  32  165  822]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.35      0.38       328\n",
      "           1       0.92      0.93      0.93      4211\n",
      "           2       0.81      0.81      0.81      1019\n",
      "\n",
      "    accuracy                           0.87      5558\n",
      "   macro avg       0.72      0.70      0.71      5558\n",
      "weighted avg       0.87      0.87      0.87      5558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "y_pred_dt = classifier_dt.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_dt)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "880c10d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.805865\n"
     ]
    }
   ],
   "source": [
    "#naviebias\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_prednb = mnb.predict(X_test)\n",
    "print('Accuracy : %f' %(accuracy_score(y_prednb, y_test)))\n",
    "score_mnbt = round(accuracy_score(y_prednb,y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e98a8151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.894746\n"
     ]
    }
   ],
   "source": [
    "#SVC classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "SVCmodel = LinearSVC()\n",
    "SVCmodel.fit(X_train, y_train)\n",
    "y_predsv = SVCmodel.predict(X_test)\n",
    "print('Accuracy : %f' %(accuracy_score(y_predsv, y_test)))\n",
    "score_svt = round(accuracy_score(y_predsv,y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e57a0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=0.5)\n",
    "# Train Adaboost Classifer\n",
    "ada = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "caaac150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.07      0.13       328\n",
      "           1       0.94      0.89      0.92      4211\n",
      "           2       0.65      0.95      0.77      1019\n",
      "\n",
      "    accuracy                           0.86      5558\n",
      "   macro avg       0.72      0.64      0.60      5558\n",
      "weighted avg       0.86      0.86      0.84      5558\n",
      "\n",
      "[[  23  215   90]\n",
      " [   7 3766  438]\n",
      " [  10   38  971]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7adc72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:27:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#XGBOOST\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=3,n_estimators=300,learning_rate=0.05)\n",
    "    \n",
    "xgb_clf.fit(X_train,y_train)\n",
    "y_pred_XG = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5359f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  77  168   83]\n",
      " [  34 3854  323]\n",
      " [  11   40  968]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.23      0.34       328\n",
      "           1       0.95      0.92      0.93      4211\n",
      "           2       0.70      0.95      0.81      1019\n",
      "\n",
      "    accuracy                           0.88      5558\n",
      "   macro avg       0.76      0.70      0.69      5558\n",
      "weighted avg       0.89      0.88      0.87      5558\n",
      "\n",
      "88.1432169845268\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_XG))\n",
    "print(classification_report(y_test, y_pred_XG))\n",
    "print(accuracy_score(y_test,y_pred_XG)*100)\n",
    "score_svm = accuracy_score(y_test,y_pred_XG)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38dc79",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4f8db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27786, 2000) (27786,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Create word vector (count)\n",
    "CountVector = CountVectorizer(max_features=2000)\n",
    "\n",
    "X = CountVector.fit_transform(data.text).toarray()\n",
    "y = data.label.values\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f46059ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train data has shape (22228, 2000) and their label's shape (22228,)\n",
      "X test data has shape (5558, 2000) and their label's shape (5558,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=555)\n",
    "print(f\"X train data has shape {X_train.shape} and their label's shape {y_train.shape}\")\n",
    "print(f\"X test data has shape {X_test.shape} and their label's shape {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f6ea17c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-e51bedc239e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Predict using RandomForest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m555\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \"\"\"\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Predict using RandomForest\n",
    "rf = RandomForestClassifier(random_state=555)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "print('Accuracy : %f' %(accuracy_score(y_pred, y_test)))\n",
    "score_rf = round(accuracy_score(y_pred,y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_prednb = mnb.predict(X_test)\n",
    "print('Accuracy : %f' %(accuracy_score(y_prednb, y_test)))\n",
    "score_nb = round(accuracy_score(y_prednb,y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba816e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train, y_train)\n",
    "y_predlr = mnb.predict(X_test)\n",
    "print('Accuracy : %f' %(accuracy_score(y_predlr, y_test)))\n",
    "score_lr = round(accuracy_score(y_predlr,y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=25)\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preddt = tree_clf.predict(X_test)\n",
    "print('Accuracy : %f' %(accuracy_score(y_preddt, y_test)))\n",
    "score_dt = round(accuracy_score(y_preddt,y_test)*100,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed61e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "SVCmodel = LinearSVC()\n",
    "SVCmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predsv = SVCmodel.predict(X_test)\n",
    "print('Accuracy : %f' %(accuracy_score(y_predsv, y_test)))\n",
    "score_svt = round(accuracy_score(y_predsv,y_test)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d30913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=0.5)\n",
    "# Train Adaboost Classifer\n",
    "ada = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = ada.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=3,n_estimators=300,learning_rate=0.05)\n",
    "    \n",
    "xgb_clf.fit(X_train,y_train)\n",
    "y_pred_XG = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dedca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_XG))\n",
    "print(classification_report(y_test, y_pred_XG))\n",
    "print(accuracy_score(y_test,y_pred_XG)*100)\n",
    "score_svm = accuracy_score(y_test,y_pred_XG)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7d320",
   "metadata": {},
   "source": [
    "# Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5fa1576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(n_estimators=500,\n",
       "                                                     random_state=0)),\n",
       "                             ('svm', SVC(probability=True, random_state=0)),\n",
       "                             ('log', LogisticRegression(random_state=0))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "rfClf = RandomForestClassifier(n_estimators=500, random_state=0) # 500 trees.\n",
    "svmClf = SVC(probability=True, random_state=0) # probability calculation\n",
    "logClf = LogisticRegression(random_state=0)\n",
    "#nbclf = GaussianNB(random_state=0)\n",
    "\n",
    "# constructing the ensemble classifier by mentioning the individual classifiers.\n",
    "clf2 = VotingClassifier(estimators = [('rf',rfClf), ('svm',svmClf), ('log', logClf)], voting='soft') \n",
    "\n",
    "# train the ensemble classifier\n",
    "clf2.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51e54741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Voting classifier on TRAIN is :  96.09 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "x_actual, x_pred = y_train, clf2.predict(X_train)\n",
    "\n",
    "accuracy_score_VC_train = accuracy_score(x_actual, x_pred)\n",
    "\n",
    "print('The accuracy score of Voting classifier on TRAIN is : ',round(accuracy_score_VC_train * 100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46d7eb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Voting classifier on Test is :  89.6 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "y_actual, y_pred = y_test, clf2.predict(X_test)\n",
    "\n",
    "accuracy_score_VC_test = accuracy_score(y_actual, y_pred)\n",
    "\n",
    "print('The accuracy score of Voting classifier on Test is : ',round(accuracy_score_VC_test * 100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08314c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(n_estimators=500,\n",
       "                                                     random_state=0)),\n",
       "                             ('svm', SVC(probability=True, random_state=0)),\n",
       "                             ('NB', GaussianNB())],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "rfClf = RandomForestClassifier(n_estimators=500, random_state=0) # 500 trees.\n",
    "svmClf = SVC(probability=True, random_state=0) # probability calculation\n",
    "nbclf = GaussianNB()\n",
    "\n",
    "# constructing the ensemble classifier by mentioning the individual classifiers.\n",
    "clf2 = VotingClassifier(estimators = [('rf',rfClf), ('svm',svmClf), ('NB', nbclf)], voting='soft') \n",
    "\n",
    "# train the ensemble classifier\n",
    "clf2.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "043b9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Voting classifier on Test is :  88.07 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "y_actual, y_pred = y_test, clf2.predict(X_test)\n",
    "\n",
    "accuracy_score_VC_test = accuracy_score(y_actual, y_pred)\n",
    "\n",
    "print('The accuracy score of Voting classifier on Test is : ',round(accuracy_score_VC_test * 100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a8ab4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:37:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('NB', GaussianNB()),\n",
       "                             ('svm', SVC(probability=True, random_state=0)),\n",
       "                             ('XB',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            gamma=None, gpu_id=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.05,\n",
       "                                            max_delta_step=None, max_depth=3,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=300, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=3,n_estimators=300,learning_rate=0.05)\n",
    "\n",
    "#rfClf = RandomForestClassifier(n_estimators=500, random_state=0) # 500 trees.\n",
    "svmClf = SVC(probability=True, random_state=0) # probability calculation\n",
    "nbclf = GaussianNB()\n",
    "\n",
    "# constructing the ensemble classifier by mentioning the individual classifiers.\n",
    "clf2 = VotingClassifier(estimators = [('NB',nbclf), ('svm',svmClf), ('XB', xgb_clf)], voting='soft') \n",
    "\n",
    "# train the ensemble classifier\n",
    "clf2.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "befa542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Voting classifier on Test is :  87.41 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "y_actual, y_pred = y_test, clf2.predict(X_test)\n",
    "\n",
    "accuracy_score_VC_test = accuracy_score(y_actual, y_pred)\n",
    "\n",
    "print('The accuracy score of Voting classifier on Test is : ',round(accuracy_score_VC_test * 100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c9ebcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.855703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8557034904641958"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_WKNN = KNeighborsClassifier(algorithm=\"auto\",n_neighbors=13,weights='distance')\n",
    "clf_WKNN.fit(X_train, y_train)\n",
    "y_pred_WKNN  = clf_WKNN.predict(X_test)\n",
    "print('Accuracy : %f' %(accuracy_score(y_pred_WKNN, y_test)))\n",
    "score_WKNN = round(accuracy_score(y_pred_WKNN,y_test)*100,2)\n",
    "score_WKNN = accuracy_score(y_pred_WKNN,y_test)\n",
    "score_WKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb730537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:31:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('AB', AdaBoostClassifier(learning_rate=0.5)),\n",
       "                             ('XG',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            gamma=None, gpu_id=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.05,\n",
       "                                            max_delta_step=None, max_depth=3,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=300, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                             ('WKNN',\n",
       "                              KNeighborsClassifier(n_neighbors=13,\n",
       "                                                   weights='distance'))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_WKNN = KNeighborsClassifier(algorithm=\"auto\",n_neighbors=13,weights='distance')\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=0.5)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(max_depth=3,n_estimators=300,learning_rate=0.05)\n",
    "\n",
    "\n",
    "# constructing the ensemble classifier by mentioning the individual classifiers.\n",
    "clf2 = VotingClassifier(estimators = [('AB',abc), ('XG',xgb_clf), ('WKNN', clf_WKNN)], voting='soft') \n",
    "\n",
    "# train the ensemble classifier\n",
    "clf2.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "090bb37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Voting classifier on Test is :  87.32 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "y_actual, y_pred = y_test, clf2.predict(X_test)\n",
    "\n",
    "accuracy_score_VC_test = accuracy_score(y_actual, y_pred)\n",
    "\n",
    "print('The accuracy score of Voting classifier on Test is : ',round(accuracy_score_VC_test * 100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e5f296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-371e15e01dfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#Fitting ANN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "#ann classifier\n",
    "#Initialising ANN\n",
    "import tensorflow as tf\n",
    "ann = tf.keras.models.Sequential()\n",
    "#Adding First Hidden Layer\n",
    "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))\n",
    "#Adding Second Hidden Layer\n",
    "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))\n",
    "#Adding Output Layer\n",
    "ann.add(tf.keras.layers.Dense(units=3,activation=\"softmax\"))\n",
    "#Compiling ANN\n",
    "ann.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "#Fitting ANN\n",
    "ann.fit(X_train,y_train,batch_size=32,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61042cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(n_estimators=500,\n",
       "                                                     random_state=0)),\n",
       "                             ('svm', SVC(probability=True, random_state=0))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "rfClf = RandomForestClassifier(n_estimators=500, random_state=0) # 500 trees.\n",
    "svmClf = SVC(probability=True, random_state=0) # probability calculation\n",
    "# logClf = LogisticRegression(random_state=0)\n",
    "#nbclf = GaussianNB(random_state=0)\n",
    "\n",
    "# constructing the ensemble classifier by mentioning the individual classifiers.\n",
    "clf2 = VotingClassifier(estimators = [('rf',rfClf), ('svm',svmClf)], voting='soft') \n",
    "\n",
    "# train the ensemble classifier\n",
    "clf2.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0483842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Voting classifier on Test is :  90.7 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "y_actual, y_pred = y_test, clf2.predict(X_test)\n",
    "\n",
    "accuracy_score_VC_test = accuracy_score(y_actual, y_pred)\n",
    "\n",
    "print('The accuracy score of Voting classifier on Test is : ',round(accuracy_score_VC_test * 100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90973039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of Voting classifier on Test is :  32.37 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)   \n",
    "kmeans.fit(X_train, y_train)\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "y_actual, y_pred = y_test, kmeans.predict(X_test)\n",
    "\n",
    "accuracy_score_VC_test = accuracy_score(y_actual, y_pred)\n",
    "\n",
    "print('The accuracy score of Voting classifier on Test is : ',round(accuracy_score_VC_test * 100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a3bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
